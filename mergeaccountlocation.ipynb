{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geographical location of accounts\n",
    "\n",
    "* Merge the \"Goldmine Territory and 2018 Trade Shows.xlsx\" account territory with the accounts in the yaerly dataset (take 2024 sales dataset for example)\n",
    "* Examine whether all the accounts have a geagraphic location recorded in Client\"s datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Examine the Account Location File\n",
    "\n",
    "* Examine the total number of accounts (companies) recorded in the xlsx file.\n",
    "* Examine the number of accounts that has a geographic territory recorded in the dataset\n",
    "* create a composite key for each account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        C1AccountNo        CXRecords Residence  Cmpy Sales Proj 2012  \\\n",
      "0  A2061733055&RY+5  9147BAL$5?9W W<       NaN                   NaN   \n",
      "1  A2061733056$=L._  9S575WH#XX 1 YU       NaN                   NaN   \n",
      "2  A2061733058#?\\R?  CENFZ26$1HH03{G       NaN                   NaN   \n",
      "3  A2061733058#^F7+  91470IF(9`JJ W<       NaN                   NaN   \n",
      "4  A2061733059#G9O;  91470JW%5D/N W<       NaN                   NaN   \n",
      "\n",
      "   Comp Terr   Latitude  UPRJISLE11 Record Confirm  UREORDCALL      Rebate  \\\n",
      "0    Central   0.000000         NaN     1989-01-01         NaN         NaN   \n",
      "1    Western  37.773032         NaN     1989-01-01         NaN         NaN   \n",
      "2    Midwest  44.048492         NaN     1989-01-01         NaN         NaN   \n",
      "3    Central  41.579921         NaN     1989-01-01         NaN         NaN   \n",
      "4  Northeast  27.984706         NaN     1989-01-01         NaN  4%>$25,000   \n",
      "\n",
      "  Trd Shw 2018 Facebook Link  \n",
      "0          NaN           NaN  \n",
      "1          NaN           NaN  \n",
      "2          NaN           NaN  \n",
      "3          NaN           NaN  \n",
      "4          NaN           NaN  \n"
     ]
    }
   ],
   "source": [
    "geo = pd.read_excel(\"Goldmine Territory and 2018 Trade Shows.xlsx\")\n",
    "print(geo.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124414\n",
      "C1AccountNo                  0\n",
      "CXRecords                    0\n",
      "Residence               106473\n",
      "Cmpy Sales Proj 2012    124152\n",
      "Comp Terr                 6559\n",
      "Latitude                     0\n",
      "UPRJISLE11              124414\n",
      "Record Confirm               0\n",
      "UREORDCALL              124281\n",
      "Rebate                  100567\n",
      "Trd Shw 2018            123043\n",
      "Facebook Link           113514\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Examine the missing values in each column\n",
    "# Check the number of missing values in each column\n",
    "missing_values = geo.isnull().sum()\n",
    "\n",
    "print(len(geo))\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          C1AccountNo        CXRecords Residence  Cmpy Sales Proj 2012  \\\n",
      "73   A2061733056(X^F!  91470FL)3O[F W<       NaN                   NaN   \n",
      "120  A2061733081#A_?%  91471EC!WY*C W<       NaN                   NaN   \n",
      "190  A2061733082(QC5#  91471FM!.M_\\ W<       NaN                   NaN   \n",
      "204  A2061733091$,4;U  91471RX%9(R( W<       NaN                   NaN   \n",
      "217  A2061733060!-W P  91470L2#:#8F W<       NaN                   NaN   \n",
      "\n",
      "    Comp Terr   Latitude  UPRJISLE11 Record Confirm  UREORDCALL Rebate  \\\n",
      "73        NaN  41.698611         NaN     1989-01-01         NaN    NaN   \n",
      "120       NaN   0.000000         NaN     1989-01-01         NaN      Y   \n",
      "190       NaN   0.000000         NaN     1989-01-01         NaN    NaN   \n",
      "204       NaN  41.698958         NaN     1989-01-01         NaN    NaN   \n",
      "217       NaN   0.000000         NaN     1989-01-01         NaN    NaN   \n",
      "\n",
      "    Trd Shw 2018 Facebook Link  \n",
      "73           NaN           NaN  \n",
      "120          NaN           NaN  \n",
      "190          NaN           NaN  \n",
      "204          NaN           NaN  \n",
      "217          NaN           NaN  \n",
      "C1AccountNo                A2061733181$65&{\n",
      "CXRecords                   91475A0&W_-< W<\n",
      "Residence                               NaN\n",
      "Cmpy Sales Proj 2012                    NaN\n",
      "Comp Terr                               NaN\n",
      "Latitude                                0.0\n",
      "UPRJISLE11                              NaN\n",
      "Record Confirm          1989-01-01 00:00:00\n",
      "UREORDCALL                              NaN\n",
      "Rebate                                  NaN\n",
      "Trd Shw 2018                            NaN\n",
      "Facebook Link                           NaN\n",
      "Name: 1032, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#The above result shows that there are comapny without Terro value but with Latitude value\n",
    "#Examine the rows that satisfy this situation\n",
    "# Filter rows where 'Comp Terr' is NaN but 'Latitude' is not NaN\n",
    "missing_comp_terr_with_latitude = geo[geo['Comp Terr'].isna() & geo['Latitude'].notna()]\n",
    "\n",
    "print(missing_comp_terr_with_latitude.head())\n",
    "print(missing_comp_terr_with_latitude.iloc[10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Michael\\AppData\\Local\\Temp\\ipykernel_68084\\2166577889.py:18: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  closest_row = reference_df.iloc[(reference_df['Latitude'] - latitude).abs().argsort()[:1]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        C1AccountNo        CXRecords Residence  Cmpy Sales Proj 2012  \\\n",
      "0  A2061733055&RY+5  9147BAL$5?9W W<       NaN                   NaN   \n",
      "1  A2061733056$=L._  9S575WH#XX 1 YU       NaN                   NaN   \n",
      "2  A2061733058#?\\R?  CENFZ26$1HH03{G       NaN                   NaN   \n",
      "3  A2061733058#^F7+  91470IF(9`JJ W<       NaN                   NaN   \n",
      "4  A2061733059#G9O;  91470JW%5D/N W<       NaN                   NaN   \n",
      "\n",
      "   Comp Terr   Latitude  UPRJISLE11 Record Confirm  UREORDCALL      Rebate  \\\n",
      "0    Central   0.000000         NaN     1989-01-01         NaN         NaN   \n",
      "1    Western  37.773032         NaN     1989-01-01         NaN         NaN   \n",
      "2    Midwest  44.048492         NaN     1989-01-01         NaN         NaN   \n",
      "3    Central  41.579921         NaN     1989-01-01         NaN         NaN   \n",
      "4  Northeast  27.984706         NaN     1989-01-01         NaN  4%>$25,000   \n",
      "\n",
      "  Trd Shw 2018 Facebook Link  \n",
      "0          NaN           NaN  \n",
      "1          NaN           NaN  \n",
      "2          NaN           NaN  \n",
      "3          NaN           NaN  \n",
      "4          NaN           NaN  \n",
      "\n",
      "          C1AccountNo        CXRecords Residence  Cmpy Sales Proj 2012  \\\n",
      "120  A2061733081#A_?%  91471EC!WY*C W<       NaN                   NaN   \n",
      "190  A2061733082(QC5#  91471FM!.M_\\ W<       NaN                   NaN   \n",
      "217  A2061733060!-W P  91470L2#:#8F W<       NaN                   NaN   \n",
      "534  A2061733116%^.I\\  91472R6$#E3R W<       NaN                   NaN   \n",
      "673  A2061733130 T#>]  91473A4%)[-* W<       NaN                   NaN   \n",
      "\n",
      "    Comp Terr  Latitude  UPRJISLE11 Record Confirm  UREORDCALL Rebate  \\\n",
      "120       NaN       0.0         NaN     1989-01-01         NaN      Y   \n",
      "190       NaN       0.0         NaN     1989-01-01         NaN    NaN   \n",
      "217       NaN       0.0         NaN     1989-01-01         NaN    NaN   \n",
      "534       NaN       0.0         NaN     1989-01-01         NaN    NaN   \n",
      "673       NaN       0.0         NaN     1989-01-01         NaN    NaN   \n",
      "\n",
      "    Trd Shw 2018 Facebook Link  \n",
      "120          NaN           NaN  \n",
      "190          NaN           NaN  \n",
      "217          NaN           NaN  \n",
      "534          NaN           NaN  \n",
      "673          NaN           NaN  \n",
      "5053\n"
     ]
    }
   ],
   "source": [
    "# while some attitude is 0.00 (no value in this case), some latitude has a non 0 value but without Company Terr valure\n",
    "#filter out those rows and assign similar company Terr value to those rows\n",
    "\n",
    "#This is for testing the matching code\n",
    "\n",
    "geo_copy = geo.copy(deep=True)\n",
    "\n",
    "#Filter rows with valid Latitude (> 0.00) and Comp Terr values as reference examples\n",
    "reference_geo = geo_copy[(geo_copy['Latitude'] > 0.00) & geo_copy['Comp Terr'].notna()]\n",
    "\n",
    "#Filter rows that have a valid Latitude (> 0.00) but missing Comp Terr\n",
    "missing_comp_terr_rows = geo_copy[(geo_copy['Latitude'] > 0.00) & geo_copy['Comp Terr'].isna()]\n",
    "\n",
    "#Function to find the closest latitude and its corresponding Comp Terr\n",
    "def find_closest_latitude(row, reference_df):\n",
    "    latitude = row['Latitude']\n",
    "    # Find the row in the reference data with the closest latitude\n",
    "    closest_row = reference_df.iloc[(reference_df['Latitude'] - latitude).abs().argsort()[:1]]\n",
    "    return closest_row['Comp Terr'].values[0]  # Return the closest Comp Terr value\n",
    "\n",
    "#Assign the closest Comp Terr value to rows with missing Comp Terr in the dataframe\n",
    "geo_copy.loc[missing_comp_terr_rows.index, 'Comp Terr'] = missing_comp_terr_rows.apply(find_closest_latitude, reference_df=reference_geo, axis=1)\n",
    "\n",
    "missing_values_test = geo_copy.isnull().sum()\n",
    "\n",
    "missing_comp_terr_with_latitude_test = geo_copy[geo_copy['Comp Terr'].isna() & geo_copy['Latitude'].notna()]\n",
    "\n",
    "print(geo_copy.head())\n",
    "print(missing_comp_terr_with_latitude_test.head())\n",
    "print(len(missing_comp_terr_with_latitude_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5053\n",
      "C1AccountNo                  0\n",
      "CXRecords                    0\n",
      "Residence               106473\n",
      "Cmpy Sales Proj 2012    124152\n",
      "Comp Terr                 5053\n",
      "Latitude                     0\n",
      "UPRJISLE11              124414\n",
      "Record Confirm               0\n",
      "UREORDCALL              124281\n",
      "Rebate                  100567\n",
      "Trd Shw 2018            123043\n",
      "Facebook Link           113514\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(len(missing_comp_terr_with_latitude_test))\n",
    "print(missing_values_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary stat for Account Geo Location Info\n",
    "* Currently there are 6559 accounts inside thw dataset without geographical location (Company Terr is NA and Latitude == 0.000 or Latitude has a value other than 0)\n",
    "* If we use the existing Company terr and Latitude to impute the rows that as a non 0 Latitude and NA Company terr, there will be 5053 rows left that we can not determine the location of use a close latitude for imputation\n",
    "* Consider that the missing value is less than 6% of the entire dataset, we could first merge the dataset for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge the Company Location value with the annual sales dataset\n",
    "\n",
    "* create composite key for the geo dataframe\n",
    "* examine whether the same key exists in the 2023 sales and 2024 sales dataset\n",
    "* Merge the 2023 sales dataset\n",
    "* Merge the 2024 sales dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        C1AccountNo        CXRecords                     composite_key\n",
      "0  A2061733055&RY+5  9147BAL$5?9W W<  A2061733055&RY+5-9147BAL$5?9W W<\n",
      "1  A2061733056$=L._  9S575WH#XX 1 YU  A2061733056$=L._-9S575WH#XX 1 YU\n",
      "2  A2061733058#?\\R?  CENFZ26$1HH03{G  A2061733058#?\\R?-CENFZ26$1HH03{G\n",
      "3  A2061733058#^F7+  91470IF(9`JJ W<  A2061733058#^F7+-91470IF(9`JJ W<\n",
      "4  A2061733059#G9O;  91470JW%5D/N W<  A2061733059#G9O;-91470JW%5D/N W<\n"
     ]
    }
   ],
   "source": [
    "# Create a composite key by combining 'C1AccountNo' and 'CXRecords' columns\n",
    "geo['composite_key'] = geo['C1AccountNo'] + '-' + geo['CXRecords']\n",
    "\n",
    "\n",
    "print(geo[['C1AccountNo', 'CXRecords', 'composite_key']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124414, 20)\n",
      "(124414, 18)\n"
     ]
    }
   ],
   "source": [
    "#read in the 2023 and 2024 sales datasets\n",
    "\n",
    "sales2023 = pd.read_excel('Crystal D 2023 sales.xlsx')\n",
    "sales2024 = pd.read_excel('Crystal D 2024 sales.xlsx')\n",
    "\n",
    "print(sales2023.shape)\n",
    "print(sales2024.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        C1AccountNo        CXRecords                     composite_key  \\\n",
      "0  A2061733055&RY+5  91470ER(#7ZS W<  A2061733055&RY+5-91470ER(#7ZS W<   \n",
      "1  A2061733055)S{G]  91470F3(E^Q/ W<  A2061733055)S{G]-91470F3(E^Q/ W<   \n",
      "2  A2061733056$FX$L  91470G4$R)&< W<  A2061733056$FX$L-91470G4$R)&< W<   \n",
      "3  A2061733057#*N-2  91470GQ%![I! W<  A2061733057#*N-2-91470GQ%![I! W<   \n",
      "4  A2061733058#^F7+  91470IF(9`JJ W<  A2061733058#^F7+-91470IF(9`JJ W<   \n",
      "\n",
      "   2023 Jan  2023 Feb  2023 Mar  2023 Apr  2023 May  2023 Jun  2023 Jul  \\\n",
      "0      0.00      0.00      0.00      0.00      0.00       0.0       0.0   \n",
      "1      0.00      0.00      0.00      0.00      0.00       0.0       0.0   \n",
      "2      0.00      0.00      0.00      0.00      0.00       0.0       0.0   \n",
      "3  14960.72   1582.26   2425.43   4863.82  13153.96       0.0       0.0   \n",
      "4      0.00      0.00      0.00      0.00      0.00       0.0       0.0   \n",
      "\n",
      "   2023 Aug  2023 Sep  2023 Oct  2023 Nov  2023 Dec   2023 Q1   2023 Q2  \\\n",
      "0       0.0       0.0       0.0       0.0       0.0      0.00      0.00   \n",
      "1       0.0       0.0       0.0       0.0       0.0      0.00      0.00   \n",
      "2       0.0       0.0       0.0       0.0       0.0      0.00      0.00   \n",
      "3       0.0       0.0       0.0       0.0       0.0  18968.41  18017.78   \n",
      "4       0.0       0.0       0.0       0.0       0.0      0.00      0.00   \n",
      "\n",
      "   2023 Q3  2023 Q4  2023 Sales  \n",
      "0      0.0      0.0           0  \n",
      "1      0.0      0.0           0  \n",
      "2      0.0      0.0           0  \n",
      "3      0.0      0.0       55561  \n",
      "4      0.0      0.0           0  \n"
     ]
    }
   ],
   "source": [
    "print(sales2023.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Composite keys in geo but not in sales2023:\n",
      "set()\n",
      "\n",
      "Composite keys in sales2023 but not in geo:\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "#Examine whether the composite key exists in both datasets\n",
    "# Convert the 'composite_key' columns of both dataframes to sets\n",
    "geo_keys = set(geo['composite_key'])\n",
    "sales_keys = set(sales2023['composite_key'])\n",
    "\n",
    "keys_in_geo_not_in_sales = geo_keys - sales_keys\n",
    "keys_in_sales_not_in_geo = sales_keys - geo_keys\n",
    "\n",
    "print(\"Composite keys in geo but not in sales2023:\")\n",
    "print(keys_in_geo_not_in_sales)\n",
    "\n",
    "print(\"\\nComposite keys in sales2023 but not in geo:\")\n",
    "print(keys_in_sales_not_in_geo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        C1AccountNo        CXRecords                     composite_key  \\\n",
      "0  A2061733055&RY+5  91470ER(#7ZS W<  A2061733055&RY+5-91470ER(#7ZS W<   \n",
      "1  A2061733055)S{G]  91470F3(E^Q/ W<  A2061733055)S{G]-91470F3(E^Q/ W<   \n",
      "2  A2061733056$FX$L  91470G4$R)&< W<  A2061733056$FX$L-91470G4$R)&< W<   \n",
      "3  A2061733057#*N-2  91470GQ%![I! W<  A2061733057#*N-2-91470GQ%![I! W<   \n",
      "4  A2061733058#^F7+  91470IF(9`JJ W<  A2061733058#^F7+-91470IF(9`JJ W<   \n",
      "\n",
      "   2023 Jan  2023 Feb  2023 Mar  2023 Apr  2023 May  2023 Jun  2023 Jul  ...  \\\n",
      "0      0.00      0.00      0.00      0.00      0.00       0.0       0.0  ...   \n",
      "1      0.00      0.00      0.00      0.00      0.00       0.0       0.0  ...   \n",
      "2      0.00      0.00      0.00      0.00      0.00       0.0       0.0  ...   \n",
      "3  14960.72   1582.26   2425.43   4863.82  13153.96       0.0       0.0  ...   \n",
      "4      0.00      0.00      0.00      0.00      0.00       0.0       0.0  ...   \n",
      "\n",
      "   2023 Oct  2023 Nov  2023 Dec   2023 Q1   2023 Q2  2023 Q3  2023 Q4  \\\n",
      "0       0.0       0.0       0.0      0.00      0.00      0.0      0.0   \n",
      "1       0.0       0.0       0.0      0.00      0.00      0.0      0.0   \n",
      "2       0.0       0.0       0.0      0.00      0.00      0.0      0.0   \n",
      "3       0.0       0.0       0.0  18968.41  18017.78      0.0      0.0   \n",
      "4       0.0       0.0       0.0      0.00      0.00      0.0      0.0   \n",
      "\n",
      "   2023 Sales  Comp Terr   Latitude  \n",
      "0           0    Central   0.000000  \n",
      "1           0    Central   0.000000  \n",
      "2           0    Central  42.019159  \n",
      "3       55561    Central  42.135659  \n",
      "4           0    Central  41.579921  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "124414\n"
     ]
    }
   ],
   "source": [
    "#Since there are no key that is mismatched in the data frames, merge the geo info to the sales 2023 data frame\n",
    "# Merge the 'Comp Terr' and 'Latitude' columns from geo into sales2023 based on the composite_key\n",
    "sales2023 = sales2023.merge(geo[['composite_key', 'Comp Terr', 'Latitude']], on='composite_key', how='left')\n",
    "\n",
    "# Display the result to check if the merge worked correctly\n",
    "print(sales2023.head())\n",
    "print((len(sales2023)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6559\n"
     ]
    }
   ],
   "source": [
    "#Examine the rows in the sales2023 which the Company Terr is NA and Latitude is not NA, check whether the number of rows is 6559\n",
    "rows_with_latitude_no_comp_terr = sales2023[(sales2023['Latitude'].notna()) & (sales2023['Comp Terr'].isna())]\n",
    "\n",
    "print(len(rows_with_latitude_no_comp_terr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        C1AccountNo        CXRecords                     composite_key  \\\n",
      "0  A2061733055&RY+5  91470ER(#7ZS W<  A2061733055&RY+5-91470ER(#7ZS W<   \n",
      "1  A2061733055)S{G]  91470F3(E^Q/ W<  A2061733055)S{G]-91470F3(E^Q/ W<   \n",
      "2  A2061733056$FX$L  91470G4$R)&< W<  A2061733056$FX$L-91470G4$R)&< W<   \n",
      "3  A2061733057#*N-2  91470GQ%![I! W<  A2061733057#*N-2-91470GQ%![I! W<   \n",
      "4  A2061733058#^F7+  91470IF(9`JJ W<  A2061733058#^F7+-91470IF(9`JJ W<   \n",
      "\n",
      "   2024 Jan  2024 Feb  2024 Mar  2024 Apr  2024 May  2024 Jun  2024 Jul  \\\n",
      "0       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "1       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "2       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "3       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "4       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "\n",
      "   2024 Aug  2024 Sep  2024 Oct  2024 Nov  2024 Dec  2024 Q1  2024 Q2  \\\n",
      "0       0.0         0         0         0         0      0.0      0.0   \n",
      "1       0.0         0         0         0         0      0.0      0.0   \n",
      "2       0.0         0         0         0         0      0.0      0.0   \n",
      "3       0.0         0         0         0         0      0.0      0.0   \n",
      "4       0.0         0         0         0         0      0.0      0.0   \n",
      "\n",
      "   2024 Sales  \n",
      "0           0  \n",
      "1           0  \n",
      "2           0  \n",
      "3       44328  \n",
      "4           0  \n"
     ]
    }
   ],
   "source": [
    "print(sales2024.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Composite keys in geo but not in sales2024:\n",
      "set()\n",
      "\n",
      "Composite keys in sales2024 but not in geo:\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "#Examine whether the composite key exists in both datasets (sales2024 and geo)\n",
    "# Convert the 'composite_key' columns of both dataframes to sets\n",
    "sales_keys_2024 = set(sales2024['composite_key'])\n",
    "\n",
    "keys_in_geo_not_in_sales_2024 = geo_keys - sales_keys_2024\n",
    "keys_in_sales_not_in_geo_2024 = sales_keys_2024 - geo_keys\n",
    "\n",
    "print(\"Composite keys in geo but not in sales2024:\")\n",
    "print(keys_in_geo_not_in_sales_2024)\n",
    "\n",
    "print(\"\\nComposite keys in sales2024 but not in geo:\")\n",
    "print(keys_in_sales_not_in_geo_2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        C1AccountNo        CXRecords                     composite_key  \\\n",
      "0  A2061733055&RY+5  91470ER(#7ZS W<  A2061733055&RY+5-91470ER(#7ZS W<   \n",
      "1  A2061733055)S{G]  91470F3(E^Q/ W<  A2061733055)S{G]-91470F3(E^Q/ W<   \n",
      "2  A2061733056$FX$L  91470G4$R)&< W<  A2061733056$FX$L-91470G4$R)&< W<   \n",
      "3  A2061733057#*N-2  91470GQ%![I! W<  A2061733057#*N-2-91470GQ%![I! W<   \n",
      "4  A2061733058#^F7+  91470IF(9`JJ W<  A2061733058#^F7+-91470IF(9`JJ W<   \n",
      "\n",
      "   2024 Jan  2024 Feb  2024 Mar  2024 Apr  2024 May  2024 Jun  2024 Jul  \\\n",
      "0       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "1       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "2       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "3       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "4       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "\n",
      "   2024 Aug  2024 Sep  2024 Oct  2024 Nov  2024 Dec  2024 Q1  2024 Q2  \\\n",
      "0       0.0         0         0         0         0      0.0      0.0   \n",
      "1       0.0         0         0         0         0      0.0      0.0   \n",
      "2       0.0         0         0         0         0      0.0      0.0   \n",
      "3       0.0         0         0         0         0      0.0      0.0   \n",
      "4       0.0         0         0         0         0      0.0      0.0   \n",
      "\n",
      "   2024 Sales Comp Terr   Latitude  \n",
      "0           0   Central   0.000000  \n",
      "1           0   Central   0.000000  \n",
      "2           0   Central  42.019159  \n",
      "3       44328   Central  42.135659  \n",
      "4           0   Central  41.579921  \n",
      "124414\n"
     ]
    }
   ],
   "source": [
    "#Since there are no key that is mismatched in the data frames, merge the geo info to the sales 2024 data frame\n",
    "# Merge the 'Comp Terr' and 'Latitude' columns from geo into sales2024 based on the composite_key\n",
    "sales2024 = sales2024.merge(geo[['composite_key', 'Comp Terr', 'Latitude']], on='composite_key', how='left')\n",
    "\n",
    "# Display the result to check if the merge worked correctly\n",
    "print(sales2024.head())\n",
    "print((len(sales2024)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6559\n"
     ]
    }
   ],
   "source": [
    "#Examine the rows in the sales2024 which the Company Terr is NA and Latitude is not NA, check whether the number of rows is 6559\n",
    "rows_with_latitude_no_comp_terr_2024 = sales2024[(sales2024['Latitude'].notna()) & (sales2024['Comp Terr'].isna())]\n",
    "\n",
    "print(len(rows_with_latitude_no_comp_terr_2024))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of two datasets and export to excel document\n",
    "\n",
    "* The keys for these datasets are the same\n",
    "* there are same number of missing geolocation info rows that needs to be further examined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame is written to Excel File successfully.\n"
     ]
    }
   ],
   "source": [
    "#Export both dataframes to excel files\n",
    "file_2023_name = 'Crystal D 2023 sales with geo.xlsx'\n",
    "file_2024_name = 'Crystal D 2024 sales with geo.xlsx'\n",
    "sales2023.to_excel(file_2023_name, index=False)\n",
    "sales2024.to_excel(file_2024_name, index=False)\n",
    "\n",
    "print('DataFrame is written to Excel File successfully.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
